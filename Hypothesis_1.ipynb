{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Summer 2017 Final Project\n",
    "\n",
    "## Personalized Medicine: Redefining Cancer Treatment\n",
    "\n",
    "\n",
    "\n",
    "#### Matt Shaffer https://github.com/planetceres \n",
    "#### Kaggle Competition: https://www.kaggle.com/c/msk-redefining-cancer-treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [discussion boards](https://www.kaggle.com/c/msk-redefining-cancer-treatment/discussion/35810#202604) on Kaggle, the classes we are trying to predict appear to be as follows:\n",
    "\n",
    "1. Likely Loss-of-function\n",
    "2. Likely Gain-of-function\n",
    "3. Neutral\n",
    "4. Loss-of-function\n",
    "5. Likely Neutral\n",
    "6. Inconclusive\n",
    "7. Gain-of-function\n",
    "8. Likely Switch-of-function\n",
    "9. Switch-of-function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import Bio\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_version = '001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'model_' + model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = '/Users/Reynard/dropbox/Data/kaggle/Personalized Medicine'\n",
    "model_directory = data_directory + '/saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_directory, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model directory if it does not exist\n",
    "if not os.path.isdir(model_directory):\n",
    "    print(\"creating directory for saved models\")\n",
    "    os.mkdir(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model to resume training or perform inference\n",
    "def load_model_from_json(model_path):\n",
    "    model = model_from_json(open(model_path + '.json').read())\n",
    "    model.load_weights(model_path + '.h5')\n",
    "    #model.compile(optimizer=rmsprop, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# Load model to resume training or perform inference\n",
    "def load_recent_model(model_path):\n",
    "    # Locate the most recent model the folder to resume training from\n",
    "    model_recent = max(glob.iglob(model_path + '*.hdf5'), key=os.path.getctime)\n",
    "    print(\"Using model at checkpoint: {}\".format(model_recent))\n",
    "    #model = model_from_json(open(model_path + '.json').read())\n",
    "    model = load_model(model_recent)\n",
    "    #model.compile(optimizer=rmsprop, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "def save_model_to_json(m, model_path):    \n",
    "    json_string = m.model.to_json()\n",
    "    open(model_path + '.json', 'w').write(json_string)\n",
    "    m.model.save_weights(model_path + '.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_op_str(data_type):\n",
    "    p = \"Done processing \" + data_type + \" data in {:.2f} seconds\"\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_blank(n):\n",
    "    print(\" \"*n, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_variants = pd.read_csv(data_directory + \"/input/training_variants\")\n",
    "test_variants = pd.read_csv(data_directory + \"/input/test_variants\")\n",
    "train_text = pd.read_csv(data_directory + \"/input/training_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "test_text = pd.read_csv(data_directory + \"/input/test_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataset will all variants\n",
    "all_variants = pd.concat([train_variants, test_variants], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set has no labels and is used only for score submission. This will be a challenge since the sample size is small, and it will be hard to learn the properties of the population needed to perform inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Gene', 'Variation', 'Class']\n",
      "['ID', 'Gene', 'Variation']\n"
     ]
    }
   ],
   "source": [
    "# Test set has no labels and is used \n",
    "print(list(train_variants.columns))\n",
    "print(list(test_variants.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the gene variant data, we also have a text corpus for each example that provides the clinical evidence that human experts used to classify the genetic mutations. This is essentially an unstructured feature set, and our first task will be to map this noisy data to a set of features that can more easily be used for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Text']\n",
      "['ID', 'Text']\n"
     ]
    }
   ],
   "source": [
    "print(list(train_text.columns))\n",
    "print(list(test_text.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the text with the variant data, and separate the target values (`Class`) from the features\n",
    "train = pd.merge(train_variants, train_text, how='left', on='ID')\n",
    "y_train = train['Class'].values\n",
    "X_train = train.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the same thing with the test data, but note that there are no classes to separate as targets\n",
    "X_test = pd.merge(test_variants, test_text, how='left', on='ID')\n",
    "test_index = X_test['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create mini data sets for model building\n",
    "train_mini = train.sample(frac=0.05)\n",
    "y_train_mini = train_mini['Class'].values\n",
    "X_train_mini = train_mini.drop('Class', axis=1)\n",
    "X_test_mini = X_test.sample(frac=0.05)\n",
    "test_index_mini = X_test_mini['ID'].values\n",
    "\n",
    "# Create mini dev set for model building\n",
    "dev_mini = train.sample(frac=0.05)\n",
    "y_dev_mini = dev_mini['Class'].values\n",
    "X_dev_mini = dev_mini.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mini.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Variation Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants with `null` in the text\n",
    "# these are likely to be generated samples since they only appear in the test set\n",
    "def matches_null(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        if 'null' in v['Variation']:\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants where gene text matches variant text\n",
    "def matches_gene_variant(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        if (all_variants['Gene'][index] in v['Variation']) and ('Fusion' not in v['Variation']):\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants with `Fusion` in the text\n",
    "def matches_fusion(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        if ('Fusion' in v['Variation']) and ('Fusions' not in v['Variation']):\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants with `Exon` in the text\n",
    "def matches_exon(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        if 'Exon' in v['Variation']:\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants that match a unique variation type\n",
    "def matches_type(data):\n",
    "    # Get all unique variations with no digits in 'Variation'\n",
    "    text_type = []\n",
    "    for v in data['Variation'].unique():  \n",
    "        text_type.append(v) if (any(str.isdigit(c) for c in v) == False) else None\n",
    "    type_tokens = list(set(text_type))\n",
    "    \n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        if any(x in v['Variation'] for x in type_tokens):\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants with `_` in the text\n",
    "def matches_underscore(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        if '_' in v['Variation']:\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants with `*` in the text\n",
    "def matches_asterisk(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        if '*' in v['Variation']:\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants that match a unique variation type\n",
    "def matches_actions(data):\n",
    "    # Get all variations with an action\n",
    "    action_match = ['del', 'delins', 'dup', 'ins', 'splice', 'trunc', 'fs']\n",
    "    \n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        if any(x in v['Variation'] for x in action_match):\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants that match regex that checks for ending in a digit, \n",
    "# instead of amino acid (i.e. letter)\n",
    "def matches_end_on_position(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        m = re.search(r'\\d+$', v['Variation'])\n",
    "        if m is not None:\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants that match regex that checks for starting in a series of digits, \n",
    "# instead of amino acid (i.e. letter)\n",
    "def matches_start_on_position(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        m = re.search(r'^[0-9]+', v['Variation'])\n",
    "        if m is not None:\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants that match regex that checks for ending in a capital letter, indicating amino acid\n",
    "def matches_end_on_amino(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        m = re.search(r'[A-Z]+$', v['Variation'])\n",
    "        if m is not None:\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants that match regex that checks for starting in a capital letter, indicating amino acid\n",
    "def matches_start_on_amino(data):\n",
    "    idx = []\n",
    "    for index, v in data.iterrows():\n",
    "        m = re.search(r'^[A-Z]+', v['Variation'])\n",
    "        if m is not None:\n",
    "            idx.append(index)\n",
    "    return idx, data.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get variants that are left over after initial grouping\n",
    "def matches_none(data):\n",
    "    return list(data.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variant_groups(data):\n",
    "    # First get indices of variants with `null` in the text\n",
    "    # these are likely to be generated samples since they only appear in the test set\n",
    "    idx0, datax = matches_null(data)\n",
    "    # Get indices of variants where gene text matches variant text\n",
    "    idx1, datax = matches_gene_variant(datax)\n",
    "    # Get indices of variants where gene text matches variant text\n",
    "    idx2, datax = matches_fusion(datax)\n",
    "    # Get indices of variants with `Exon` in the text\n",
    "    idx3, datax = matches_exon(datax)\n",
    "    # Get indices of variants that match a unique variation type\n",
    "    idx4, datax = matches_type(datax)\n",
    "    # Get indices of variants with `_` in the text\n",
    "    idx5, datax = matches_underscore(datax)\n",
    "    # Get indices of variants that match a unique variation type\n",
    "    idx6, datax = matches_actions(datax)\n",
    "    # Get indices of variants with `*` in the text\n",
    "    idx7, datax = matches_asterisk(datax)\n",
    "    # Get variants that match regex that checks for ending in a capital letter, indicating amino acid\n",
    "    idx8, datax = matches_end_on_position(datax)\n",
    "    # Get variants that match regex that checks for ending in a capital letter, indicating amino acid\n",
    "    idx9, datax = matches_start_on_position(datax)\n",
    "    # Get variants that match regex that checks for ending in a capital letter, indicating amino acid\n",
    "    idx10, datax = matches_end_on_amino(datax)\n",
    "    # Get variants that match regex that checks for starting in a capital letter, indicating amino acid\n",
    "    idx11, datax = matches_start_on_amino(datax)\n",
    "    # Get indices of all other variants\n",
    "    idx12 = matches_none(datax)\n",
    "    \n",
    "    \n",
    "    groups = {\n",
    "        'has_null': idx0,\n",
    "        'gv': idx1,\n",
    "        'fusion': idx2,\n",
    "        'exon': idx3,\n",
    "        'type': idx4,\n",
    "        'underscore': idx5,\n",
    "        'actions': idx6,\n",
    "        'asterisk': idx7,\n",
    "        'end_digit': idx8,\n",
    "        'start_digit': idx9,\n",
    "        'end_amino': idx10,\n",
    "        'start_amino': idx11,\n",
    "        'outliers': idx12\n",
    "    }\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disassemble group1\n",
    "def deconstruct_null(data):\n",
    "    idx = []\n",
    "    elements = []\n",
    "    for index, v in data.iterrows():\n",
    "        if v['Variation'].startswith('null'):\n",
    "            #m = re.split(r'(\\d+|\\D+)', v['Variation']) # also extract integers?\n",
    "            m = re.split(r'\\d+', v['Variation'])\n",
    "            if len(m) == 2:\n",
    "                elements.append(m)\n",
    "                idx.append(index)\n",
    "    colnames = ['amino_state0', 'amino_state1']\n",
    "            \n",
    "    return idx, data.drop(idx), pd.DataFrame(elements, columns=colnames, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disassemble group2\n",
    "def deconstruct_gv_match(data):\n",
    "    idx = []\n",
    "    elements = []\n",
    "    for index, v in data.iterrows():\n",
    "        elements.append([v['Variation'], 1])\n",
    "        idx.append(index)\n",
    "    colnames = ['protein_token', 'protein_token_bool']\n",
    "        \n",
    "    return idx, data.drop(idx), pd.DataFrame(elements, columns=colnames, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disassemble group3\n",
    "def deconstruct_fusion(data):\n",
    "    idx = []\n",
    "    elements = []\n",
    "    for index, v in data.iterrows():\n",
    "        if v['Variation'].endswith('Fusion'):\n",
    "            m = re.split(r'\\W+', v['Variation'])\n",
    "            elements.append([m[0], m[1], 1])\n",
    "            idx.append(index)\n",
    "    colnames = ['fusion0', 'fusion1', 'fusion_bool']\n",
    "            \n",
    "    return idx, data.drop(idx), pd.DataFrame(elements, columns=colnames, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disassemble group4\n",
    "def deconstruct_exon(data):\n",
    "    idx = []\n",
    "    elements = []\n",
    "    for index, v in data.iterrows():\n",
    "        if v['Variation'].startswith('Exon'):\n",
    "            m = re.split(r'\\W+', v['Variation'])\n",
    "            if len(m) == 4:\n",
    "                m[2] = m[2] + m[3]\n",
    "                m = m[0:3]\n",
    "            elements.append([m[1], m[2], 1])\n",
    "            idx.append(index)\n",
    "    colnames = ['exon_n', 'exon_action', 'exon_bool']\n",
    "            \n",
    "    return idx, data.drop(idx), pd.DataFrame(elements, columns=colnames, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disassemble group5\n",
    "def deconstruct_type(data):\n",
    "    idx = []\n",
    "    elements = []\n",
    "    for index, v in data.iterrows():\n",
    "        elements.append([v['Variation'], 1])\n",
    "        idx.append(index)\n",
    "    colnames = ['type_token', 'type_token_bool']\n",
    "        \n",
    "    return idx, data.drop(idx), pd.DataFrame(elements, columns=colnames, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disassemble group6\n",
    "def deconstruct_underscore(data):\n",
    "    idx = []\n",
    "    elements = []\n",
    "    action_match = ['del', 'delins', 'dup', 'ins', 'splice', 'trunc', 'fs']\n",
    "\n",
    "    for index, v in data.iterrows():\n",
    "        m = re.split(r'([a-z]+)', v['Variation'])\n",
    "        for action in m:\n",
    "            if any(a == action for a in action_match):\n",
    "                action_idx = m.index(action)\n",
    "        if (len(m) == 3) and (action_idx == 1):\n",
    "            genes = m[0].split('_')\n",
    "            if len(genes) == 2:\n",
    "                elements.append([genes[0], genes[1], m[1], m[2], 1])\n",
    "                idx.append(index)\n",
    "    colnames = ['genes_state0', 'genes_state1', 'genes_action', 'genes_action_key', 'genes_action_bool']\n",
    "            \n",
    "    return idx, data.drop(idx), pd.DataFrame(elements, columns=colnames, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disassemble group7\n",
    "def deconstruct_actions(data):\n",
    "    idx = []\n",
    "    elements = []\n",
    "    action_match = ['del', 'delins', 'dup', 'ins', 'splice', 'trunc', 'fs']\n",
    "\n",
    "    for index, v in data.iterrows():\n",
    "        m = re.split(r'([a-z]+)', v['Variation'])\n",
    "        for action in m:\n",
    "            if any(a == action for a in action_match):\n",
    "                action_idx = m.index(action)  \n",
    "        if (len(m) == 3) and (action_idx == 1):\n",
    "            amino = re.split(r'\\d+', m[0])\n",
    "            if len(amino) == 2:\n",
    "                elements.append([amino[0], amino[1], m[1], m[2], 1])\n",
    "                idx.append(index)\n",
    "    colnames = ['amino_state0', 'amino_state1', 'amino_action', 'amino_action_key', 'amino_action_bool']\n",
    "            \n",
    "    return idx, data.drop(idx), pd.DataFrame(elements, columns=colnames, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disassemble group8\n",
    "def deconstruct_standard(data):\n",
    "    idx = []\n",
    "    elements = []\n",
    "\n",
    "    for index, v in data.iterrows():\n",
    "        # For sequences ending in '*'\n",
    "        if v['Variation'].endswith('*'):\n",
    "            amino = re.split(r'\\d+', v['Variation'])\n",
    "    \n",
    "            if len(amino) == 2:\n",
    "                elements.append([amino[0], amino[1], 1])\n",
    "                idx.append(index)\n",
    "        \n",
    "        # For normal Amino-Position-Amino sequences\n",
    "        if re.search(r'[A-Z]+$', v['Variation']) is not None:\n",
    "            amino = re.split(r'\\d+', v['Variation'])\n",
    "            \n",
    "            if len(amino) == 2:\n",
    "                elements.append([amino[0], amino[1], 1])\n",
    "                idx.append(index)\n",
    "        \n",
    "        # For sequences with no ending amino\n",
    "        if re.search(r'[0-9]+$', v['Variation']) is not None:\n",
    "            amino = re.split(r'\\d+', v['Variation'])\n",
    "            if len(amino) == 2:\n",
    "                elements.append([amino[0], amino[1], 1])\n",
    "                idx.append(index)\n",
    "                \n",
    "    colnames = ['amino_state0', 'amino_state1', 'amino_standard_bool']\n",
    "            \n",
    "    return idx, data.drop(idx), pd.DataFrame(elements, columns=colnames, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variant_subgroups(data, groups):\n",
    "    # Transform each group into subgroups of elements\n",
    "    idx0, datax, df0 = deconstruct_null(data.loc[groups['has_null']])\n",
    "    idx1, datax, df1 = deconstruct_gv_match(data.loc[groups['gv']])\n",
    "    idx2, datax, df2 = deconstruct_fusion(data.loc[groups['fusion']])\n",
    "    idx3, datax, df3 = deconstruct_exon(data.loc[groups['exon']])\n",
    "    idx4, datax, df4 = deconstruct_type(data.loc[groups['type']])\n",
    "    idx5, datax, df5 = deconstruct_underscore(data.loc[groups['underscore']])\n",
    "    idx6, datax, df6 = deconstruct_actions(data.loc[groups['actions']])\n",
    "    idx7, datax, df7 = deconstruct_standard(data.loc[groups['asterisk']])\n",
    "    idx8, datax, df8 = deconstruct_standard(data.loc[groups['end_digit']])\n",
    "    idx9, datax, df9 = deconstruct_standard(data.loc[groups['start_digit']])\n",
    "    idx10, datax, df10 = deconstruct_standard(data.loc[groups['end_amino']])\n",
    "    idx11, datax, df11 = deconstruct_standard(data.loc[groups['start_amino']])\n",
    "    idx12, _, df12 = deconstruct_type(data.loc[groups['outliers']])\n",
    "    \n",
    "    subgroups = {\n",
    "        'has_null': idx0,\n",
    "        'gv': idx1,\n",
    "        'fusion': idx2,\n",
    "        'exon': idx3,\n",
    "        'type': idx4,\n",
    "        'underscore': idx5,\n",
    "        'actions': idx6,\n",
    "        'asterisk': idx7,\n",
    "        'end_digit': idx8,\n",
    "        'start_digit': idx9,\n",
    "        'end_amino': idx10,\n",
    "        'start_amino': idx11,\n",
    "        'outliers': idx12\n",
    "    }\n",
    "    \n",
    "    data = data.join(df1, how='outer', lsuffix='_1L', rsuffix='_1R')\n",
    "    data = data.join(df2, how='outer', lsuffix='_2L', rsuffix='_2R')\n",
    "    data = data.join(df3, how='outer', lsuffix='_3L', rsuffix='_3R')\n",
    "    data = data.join(df4, how='outer', lsuffix='_4L', rsuffix='_4R')\n",
    "    data = data.join(df5, how='outer', lsuffix='_5L', rsuffix='_5R')\n",
    "    data = data.join(df6, how='outer', lsuffix='_6L', rsuffix='_6R')\n",
    "    data = data.join(df7, how='outer', lsuffix='_7L', rsuffix='_7R')\n",
    "    data = data.join(df8, how='outer', lsuffix='_8L', rsuffix='_8R')\n",
    "    data = data.join(df9, how='outer', lsuffix='_9L', rsuffix='_9R')\n",
    "    data = data.join(df10, how='outer', lsuffix='_10L', rsuffix='_10R')\n",
    "    data = data.join(df11, how='outer', lsuffix='_11L', rsuffix='_11R')\n",
    "    data = data.join(df12, how='outer', lsuffix='_12L', rsuffix='_12R')\n",
    "    \n",
    "    amino_col = ['amino_state0_7L',  \n",
    "                 'amino_state0_7R', \n",
    "                 'amino_state0_9L',  \n",
    "                 'amino_state0_9R',  \n",
    "                 'amino_state0_11L',  \n",
    "                 'amino_state0_11R']\n",
    "    \n",
    "    data['amino_state0'] = np.nan\n",
    "    for col in amino_col:\n",
    "        data['amino_state0'].fillna(data[col], inplace=True)\n",
    "        \n",
    "    amino1_col = ['amino_state1_7L', \n",
    "             'amino_state1_7R',\n",
    "             'amino_state1_9L', \n",
    "             'amino_state1_9R', \n",
    "             'amino_state1_11L', \n",
    "             'amino_state1_11R']\n",
    "    \n",
    "    data['amino_state1'] = np.nan\n",
    "    for col in amino1_col:\n",
    "        data['amino_state1'].fillna(data[col], inplace=True)\n",
    "        \n",
    "    type_col = ['type_token_12L', 'type_token_12R']\n",
    "    data['type_token'] = np.nan\n",
    "    for col in type_col:\n",
    "        data['type_token'].fillna(data[col], inplace=True)\n",
    "        \n",
    "    type_bool_col = ['type_token_bool_12L', 'type_token_bool_12R']\n",
    "    data['type_token_bool'] = np.nan\n",
    "    for col in type_bool_col:\n",
    "        data['type_token_bool'].fillna(data[col], inplace=True)\n",
    "        \n",
    "    amino_standard_bool_col = ['amino_standard_bool_8L', 'amino_standard_bool_8R',\n",
    "                'amino_standard_bool_10L', 'amino_standard_bool_10R']\n",
    "    data['amino_standard_bool_token'] = np.nan\n",
    "    for col in amino_standard_bool_col:\n",
    "        data['amino_standard_bool_token'].fillna(data[col], inplace=True)\n",
    "    \n",
    "    drop_cols = amino_col + amino1_col + type_col + type_bool_col + amino_standard_bool_col\n",
    "    for col in drop_cols:\n",
    "        data.drop([col], axis=1, inplace=True)\n",
    "    \n",
    "    return subgroups, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.36 s, sys: 108 ms, total: 9.47 s\n",
      "Wall time: 9.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "groups = variant_groups(all_variants)\n",
    "subgroups, all_transformed = variant_subgroups(all_variants, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>amino_state0</th>\n",
       "      <th>amino_state1</th>\n",
       "      <th>amino_standard_bool_token</th>\n",
       "      <th>type_token</th>\n",
       "      <th>type_token_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>W</td>\n",
       "      <td>*</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>Q</td>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>L</td>\n",
       "      <td>V</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CBL</td>\n",
       "      <td>V391I</td>\n",
       "      <td>V</td>\n",
       "      <td>I</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBL</td>\n",
       "      <td>V430M</td>\n",
       "      <td>V</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Y371H</td>\n",
       "      <td>Y</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CBL</td>\n",
       "      <td>C384R</td>\n",
       "      <td>C</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CBL</td>\n",
       "      <td>P395A</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CBL</td>\n",
       "      <td>K382E</td>\n",
       "      <td>K</td>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CBL</td>\n",
       "      <td>R420Q</td>\n",
       "      <td>R</td>\n",
       "      <td>Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CBL</td>\n",
       "      <td>C381A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CBL</td>\n",
       "      <td>P428L</td>\n",
       "      <td>P</td>\n",
       "      <td>L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CBL</td>\n",
       "      <td>D390Y</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Q367P</td>\n",
       "      <td>Q</td>\n",
       "      <td>P</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CBL</td>\n",
       "      <td>M374V</td>\n",
       "      <td>M</td>\n",
       "      <td>V</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Y371S</td>\n",
       "      <td>Y</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gene             Variation amino_state0 amino_state1  \\\n",
       "0   FAM58A  Truncating Mutations          NaN          NaN   \n",
       "1      CBL                 W802*            W            *   \n",
       "2      CBL                 Q249E            Q            E   \n",
       "3      CBL                 N454D            N            D   \n",
       "4      CBL                 L399V            L            V   \n",
       "5      CBL                 V391I            V            I   \n",
       "6      CBL                 V430M            V            M   \n",
       "7      CBL              Deletion          NaN          NaN   \n",
       "8      CBL                 Y371H            Y            H   \n",
       "9      CBL                 C384R            C            R   \n",
       "10     CBL                 P395A            P            A   \n",
       "11     CBL                 K382E            K            E   \n",
       "12     CBL                 R420Q            R            Q   \n",
       "13     CBL                 C381A            C            A   \n",
       "14     CBL                 P428L            P            L   \n",
       "15     CBL                 D390Y            D            Y   \n",
       "16     CBL  Truncating Mutations          NaN          NaN   \n",
       "17     CBL                 Q367P            Q            P   \n",
       "18     CBL                 M374V            M            V   \n",
       "19     CBL                 Y371S            Y            S   \n",
       "\n",
       "    amino_standard_bool_token            type_token type_token_bool  \n",
       "0                         NaN  Truncating Mutations               1  \n",
       "1                         1.0                   NaN             NaN  \n",
       "2                         1.0                   NaN             NaN  \n",
       "3                         1.0                   NaN             NaN  \n",
       "4                         1.0                   NaN             NaN  \n",
       "5                         1.0                   NaN             NaN  \n",
       "6                         1.0                   NaN             NaN  \n",
       "7                         NaN              Deletion               1  \n",
       "8                         1.0                   NaN             NaN  \n",
       "9                         1.0                   NaN             NaN  \n",
       "10                        1.0                   NaN             NaN  \n",
       "11                        1.0                   NaN             NaN  \n",
       "12                        1.0                   NaN             NaN  \n",
       "13                        1.0                   NaN             NaN  \n",
       "14                        1.0                   NaN             NaN  \n",
       "15                        1.0                   NaN             NaN  \n",
       "16                        NaN  Truncating Mutations               1  \n",
       "17                        1.0                   NaN             NaN  \n",
       "18                        1.0                   NaN             NaN  \n",
       "19                        1.0                   NaN             NaN  "
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_transformed[all_transformed.columns[19:30]][0:15]\n",
    "all_transformed[['Gene', 'Variation', 'amino_state0', 'amino_state1', 'amino_standard_bool_token', 'type_token', 'type_token_bool']][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amino Table of Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amino_table = pd.read_csv(data_directory + '/supplementary/amino_properties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amino acid</th>\n",
       "      <th>Abbreviations</th>\n",
       "      <th>Letter</th>\n",
       "      <th>Hydropathy\r\n",
       "(3 classes)</th>\n",
       "      <th>Volume\r\n",
       "(5 classes)</th>\n",
       "      <th>Chemical\r\n",
       " (7 classes)</th>\n",
       "      <th>Physicochemical\r\n",
       "(11 classes)</th>\n",
       "      <th>Charge\r\n",
       "(3 classes)</th>\n",
       "      <th>Polarity\r\n",
       "(2 classes)</th>\n",
       "      <th>Hydrogen donor or acceptor atom\r\n",
       "(4 classes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alanine</td>\n",
       "      <td>Ala</td>\n",
       "      <td>A</td>\n",
       "      <td>hydrophobic (1)</td>\n",
       "      <td>very small (1)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>uncharged(3)</td>\n",
       "      <td>nonpolar (2)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arginine</td>\n",
       "      <td>Arg</td>\n",
       "      <td>R</td>\n",
       "      <td>hydrophilic (3)</td>\n",
       "      <td>large (4)</td>\n",
       "      <td>basic (5)</td>\n",
       "      <td>basic (5)</td>\n",
       "      <td>positive charged (1)</td>\n",
       "      <td>polar (1)</td>\n",
       "      <td>donor (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asparagine</td>\n",
       "      <td>Asn</td>\n",
       "      <td>N</td>\n",
       "      <td>hydrophilic (3)</td>\n",
       "      <td>small (2)</td>\n",
       "      <td>amide (7)</td>\n",
       "      <td>amide (2)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>polar (1)</td>\n",
       "      <td>donor and acceptor (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asparagine or aspartic acid</td>\n",
       "      <td>Asx</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aspartic acid</td>\n",
       "      <td>Asp</td>\n",
       "      <td>D</td>\n",
       "      <td>hydrophilic (3)</td>\n",
       "      <td>small (2)</td>\n",
       "      <td>acidic (6)</td>\n",
       "      <td>acidic (6)</td>\n",
       "      <td>negative charged (2)</td>\n",
       "      <td>polar (1)</td>\n",
       "      <td>acceptor (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cysteine</td>\n",
       "      <td>Cys</td>\n",
       "      <td>C</td>\n",
       "      <td>hydrophobic (1)</td>\n",
       "      <td>small (2)</td>\n",
       "      <td>sulfur (3)</td>\n",
       "      <td>sulfur (3)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (2)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Glutamine</td>\n",
       "      <td>Gln</td>\n",
       "      <td>Q</td>\n",
       "      <td>hydrophilic (3)</td>\n",
       "      <td>medium (3)</td>\n",
       "      <td>amide (7)</td>\n",
       "      <td>amide (2)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>polar (1)</td>\n",
       "      <td>donor and acceptor (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Glutamic acid</td>\n",
       "      <td>Glu</td>\n",
       "      <td>E</td>\n",
       "      <td>hydrophilic (3)</td>\n",
       "      <td>medium (3)</td>\n",
       "      <td>acidic (6)</td>\n",
       "      <td>acidic (6)</td>\n",
       "      <td>negative charged (2)</td>\n",
       "      <td>polar (1)</td>\n",
       "      <td>acceptor (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glycine</td>\n",
       "      <td>Gly</td>\n",
       "      <td>G</td>\n",
       "      <td>neutral (2)</td>\n",
       "      <td>very small (1)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>G (11)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (2)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Histidine</td>\n",
       "      <td>His</td>\n",
       "      <td>H</td>\n",
       "      <td>neutral (2)</td>\n",
       "      <td>medium (3)</td>\n",
       "      <td>basic (5)</td>\n",
       "      <td>basic (5)</td>\n",
       "      <td>positive charged (1)</td>\n",
       "      <td>polar (1)</td>\n",
       "      <td>donor and acceptor (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Isoleucine</td>\n",
       "      <td>Ile</td>\n",
       "      <td>I</td>\n",
       "      <td>hydrophobic (1)</td>\n",
       "      <td>large (4)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (2)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Leucine</td>\n",
       "      <td>Leu</td>\n",
       "      <td>L</td>\n",
       "      <td>hydrophobic (1)</td>\n",
       "      <td>large (4)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (2)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Leucine or Isoleucine</td>\n",
       "      <td>Xle</td>\n",
       "      <td>J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lysine</td>\n",
       "      <td>Lys</td>\n",
       "      <td>K</td>\n",
       "      <td>hydrophilic (3)</td>\n",
       "      <td>large (4)</td>\n",
       "      <td>basic (5)</td>\n",
       "      <td>basic (5)</td>\n",
       "      <td>positive charged (1)</td>\n",
       "      <td>polar (1)</td>\n",
       "      <td>donor (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Methionine</td>\n",
       "      <td>Met</td>\n",
       "      <td>M</td>\n",
       "      <td>hydrophobic (1)</td>\n",
       "      <td>large (4)</td>\n",
       "      <td>sulfur (3)</td>\n",
       "      <td>sulfur (3)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (1)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Phenylalanine</td>\n",
       "      <td>Phe</td>\n",
       "      <td>F</td>\n",
       "      <td>hydrophobic (1)</td>\n",
       "      <td>very large (5)</td>\n",
       "      <td>aromatic (2)</td>\n",
       "      <td>F (7)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (1)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Proline</td>\n",
       "      <td>Pro</td>\n",
       "      <td>P</td>\n",
       "      <td>neutral (2)</td>\n",
       "      <td>small (2)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>P (10)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (1)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pyrrolysine</td>\n",
       "      <td>Pyl</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Selenocysteine</td>\n",
       "      <td>Sec</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Serine</td>\n",
       "      <td>Ser</td>\n",
       "      <td>S</td>\n",
       "      <td>neutral (2)</td>\n",
       "      <td>very small (1)</td>\n",
       "      <td>hydroxyl (4)</td>\n",
       "      <td>hydroxyl (4)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>polar (2)</td>\n",
       "      <td>donor and acceptor (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Threonine</td>\n",
       "      <td>Thr</td>\n",
       "      <td>T</td>\n",
       "      <td>neutral (2)</td>\n",
       "      <td>small (2)</td>\n",
       "      <td>hydroxyl (4)</td>\n",
       "      <td>hydroxyl (4)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>polar (2)</td>\n",
       "      <td>donor and acceptor (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tryptophan</td>\n",
       "      <td>Trp</td>\n",
       "      <td>W</td>\n",
       "      <td>hydrophobic (1)</td>\n",
       "      <td>very large (5)</td>\n",
       "      <td>aromatic (2)</td>\n",
       "      <td>W (8)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (1)</td>\n",
       "      <td>donor (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tyrosine</td>\n",
       "      <td>Tyr</td>\n",
       "      <td>Y</td>\n",
       "      <td>neutral (2)</td>\n",
       "      <td>very large (5)</td>\n",
       "      <td>aromatic (2)</td>\n",
       "      <td>Y (9)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>polar (2)</td>\n",
       "      <td>donor and acceptor (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Xaa</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Valine</td>\n",
       "      <td>Val</td>\n",
       "      <td>V</td>\n",
       "      <td>hydrophobic (1)</td>\n",
       "      <td>medium (3)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>aliphatic (1)</td>\n",
       "      <td>uncharged (3)</td>\n",
       "      <td>nonpolar (1)</td>\n",
       "      <td>none (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Glutamine or glutamic acid</td>\n",
       "      <td>Glx</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Amino acid Abbreviations Letter  \\\n",
       "0                       Alanine           Ala      A   \n",
       "1                      Arginine           Arg      R   \n",
       "2                    Asparagine           Asn      N   \n",
       "3   Asparagine or aspartic acid           Asx      B   \n",
       "4                 Aspartic acid           Asp      D   \n",
       "5                      Cysteine           Cys      C   \n",
       "6                     Glutamine           Gln      Q   \n",
       "7                 Glutamic acid           Glu      E   \n",
       "8                       Glycine           Gly      G   \n",
       "9                     Histidine           His      H   \n",
       "10                   Isoleucine           Ile      I   \n",
       "11                      Leucine           Leu      L   \n",
       "12        Leucine or Isoleucine           Xle      J   \n",
       "13                       Lysine           Lys      K   \n",
       "14                   Methionine           Met      M   \n",
       "15                Phenylalanine           Phe      F   \n",
       "16                      Proline           Pro      P   \n",
       "17                  Pyrrolysine           Pyl      O   \n",
       "18               Selenocysteine           Sec      U   \n",
       "19                       Serine           Ser      S   \n",
       "20                    Threonine           Thr      T   \n",
       "21                   Tryptophan           Trp      W   \n",
       "22                     Tyrosine           Tyr      Y   \n",
       "23                      Unknown           Xaa      X   \n",
       "24                       Valine           Val      V   \n",
       "25   Glutamine or glutamic acid           Glx      Z   \n",
       "\n",
       "   Hydropathy\\r\\n(3 classes) Volume\\r\\n(5 classes) Chemical\\r\\n (7 classes)  \\\n",
       "0            hydrophobic (1)        very small (1)            aliphatic (1)   \n",
       "1            hydrophilic (3)             large (4)                basic (5)   \n",
       "2            hydrophilic (3)             small (2)                amide (7)   \n",
       "3                        NaN                   NaN                      NaN   \n",
       "4            hydrophilic (3)             small (2)               acidic (6)   \n",
       "5            hydrophobic (1)             small (2)               sulfur (3)   \n",
       "6            hydrophilic (3)            medium (3)                amide (7)   \n",
       "7            hydrophilic (3)            medium (3)               acidic (6)   \n",
       "8                neutral (2)        very small (1)            aliphatic (1)   \n",
       "9                neutral (2)            medium (3)                basic (5)   \n",
       "10           hydrophobic (1)             large (4)            aliphatic (1)   \n",
       "11           hydrophobic (1)             large (4)            aliphatic (1)   \n",
       "12                       NaN                   NaN                      NaN   \n",
       "13           hydrophilic (3)             large (4)                basic (5)   \n",
       "14           hydrophobic (1)             large (4)               sulfur (3)   \n",
       "15           hydrophobic (1)        very large (5)             aromatic (2)   \n",
       "16               neutral (2)             small (2)            aliphatic (1)   \n",
       "17                       NaN                   NaN                      NaN   \n",
       "18                       NaN                   NaN                      NaN   \n",
       "19               neutral (2)        very small (1)             hydroxyl (4)   \n",
       "20               neutral (2)             small (2)             hydroxyl (4)   \n",
       "21           hydrophobic (1)        very large (5)             aromatic (2)   \n",
       "22               neutral (2)        very large (5)             aromatic (2)   \n",
       "23                       NaN                   NaN                      NaN   \n",
       "24           hydrophobic (1)            medium (3)            aliphatic (1)   \n",
       "25                       NaN                   NaN                      NaN   \n",
       "\n",
       "   Physicochemical\\r\\n(11 classes) Charge\\r\\n(3 classes)  \\\n",
       "0                    aliphatic (1)          uncharged(3)   \n",
       "1                        basic (5)  positive charged (1)   \n",
       "2                        amide (2)         uncharged (3)   \n",
       "3                              NaN                   NaN   \n",
       "4                       acidic (6)  negative charged (2)   \n",
       "5                       sulfur (3)         uncharged (3)   \n",
       "6                        amide (2)         uncharged (3)   \n",
       "7                       acidic (6)  negative charged (2)   \n",
       "8                           G (11)         uncharged (3)   \n",
       "9                        basic (5)  positive charged (1)   \n",
       "10                   aliphatic (1)         uncharged (3)   \n",
       "11                   aliphatic (1)         uncharged (3)   \n",
       "12                             NaN                   NaN   \n",
       "13                       basic (5)  positive charged (1)   \n",
       "14                      sulfur (3)         uncharged (3)   \n",
       "15                           F (7)         uncharged (3)   \n",
       "16                          P (10)         uncharged (3)   \n",
       "17                             NaN                   NaN   \n",
       "18                             NaN                   NaN   \n",
       "19                    hydroxyl (4)         uncharged (3)   \n",
       "20                    hydroxyl (4)         uncharged (3)   \n",
       "21                           W (8)         uncharged (3)   \n",
       "22                           Y (9)         uncharged (3)   \n",
       "23                             NaN                   NaN   \n",
       "24                   aliphatic (1)         uncharged (3)   \n",
       "25                             NaN                   NaN   \n",
       "\n",
       "   Polarity\\r\\n(2 classes) Hydrogen donor or acceptor atom\\r\\n(4 classes)  \n",
       "0             nonpolar (2)                                       none (4)  \n",
       "1                polar (1)                                      donor (1)  \n",
       "2                polar (1)                         donor and acceptor (3)  \n",
       "3                      NaN                                            NaN  \n",
       "4                polar (1)                                   acceptor (2)  \n",
       "5             nonpolar (2)                                       none (4)  \n",
       "6                polar (1)                         donor and acceptor (3)  \n",
       "7                polar (1)                                   acceptor (2)  \n",
       "8             nonpolar (2)                                       none (4)  \n",
       "9                polar (1)                         donor and acceptor (3)  \n",
       "10            nonpolar (2)                                       none (4)  \n",
       "11            nonpolar (2)                                       none (4)  \n",
       "12                     NaN                                            NaN  \n",
       "13               polar (1)                                      donor (1)  \n",
       "14            nonpolar (1)                                       none (4)  \n",
       "15            nonpolar (1)                                       none (4)  \n",
       "16            nonpolar (1)                                       none (4)  \n",
       "17                     NaN                                            NaN  \n",
       "18                     NaN                                            NaN  \n",
       "19               polar (2)                         donor and acceptor (3)  \n",
       "20               polar (2)                         donor and acceptor (3)  \n",
       "21            nonpolar (1)                                      donor (1)  \n",
       "22               polar (2)                         donor and acceptor (3)  \n",
       "23                     NaN                                            NaN  \n",
       "24            nonpolar (1)                                       none (4)  \n",
       "25                     NaN                                            NaN  "
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amino acid</th>\n",
       "      <th>Abbreviations</th>\n",
       "      <th>Letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alanine</td>\n",
       "      <td>Ala</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arginine</td>\n",
       "      <td>Arg</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asparagine</td>\n",
       "      <td>Asn</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asparagine or aspartic acid</td>\n",
       "      <td>Asx</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aspartic acid</td>\n",
       "      <td>Asp</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cysteine</td>\n",
       "      <td>Cys</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Glutamine</td>\n",
       "      <td>Gln</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Glutamic acid</td>\n",
       "      <td>Glu</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glycine</td>\n",
       "      <td>Gly</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Histidine</td>\n",
       "      <td>His</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Isoleucine</td>\n",
       "      <td>Ile</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Leucine</td>\n",
       "      <td>Leu</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Leucine or Isoleucine</td>\n",
       "      <td>Xle</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lysine</td>\n",
       "      <td>Lys</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Methionine</td>\n",
       "      <td>Met</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Phenylalanine</td>\n",
       "      <td>Phe</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Proline</td>\n",
       "      <td>Pro</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pyrrolysine</td>\n",
       "      <td>Pyl</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Selenocysteine</td>\n",
       "      <td>Sec</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Serine</td>\n",
       "      <td>Ser</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Threonine</td>\n",
       "      <td>Thr</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tryptophan</td>\n",
       "      <td>Trp</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tyrosine</td>\n",
       "      <td>Tyr</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Xaa</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Valine</td>\n",
       "      <td>Val</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Glutamine or glutamic acid</td>\n",
       "      <td>Glx</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Amino acid Abbreviations Letter\n",
       "0                       Alanine           Ala      A\n",
       "1                      Arginine           Arg      R\n",
       "2                    Asparagine           Asn      N\n",
       "3   Asparagine or aspartic acid           Asx      B\n",
       "4                 Aspartic acid           Asp      D\n",
       "5                      Cysteine           Cys      C\n",
       "6                     Glutamine           Gln      Q\n",
       "7                 Glutamic acid           Glu      E\n",
       "8                       Glycine           Gly      G\n",
       "9                     Histidine           His      H\n",
       "10                   Isoleucine           Ile      I\n",
       "11                      Leucine           Leu      L\n",
       "12        Leucine or Isoleucine           Xle      J\n",
       "13                       Lysine           Lys      K\n",
       "14                   Methionine           Met      M\n",
       "15                Phenylalanine           Phe      F\n",
       "16                      Proline           Pro      P\n",
       "17                  Pyrrolysine           Pyl      O\n",
       "18               Selenocysteine           Sec      U\n",
       "19                       Serine           Ser      S\n",
       "20                    Threonine           Thr      T\n",
       "21                   Tryptophan           Trp      W\n",
       "22                     Tyrosine           Tyr      Y\n",
       "23                      Unknown           Xaa      X\n",
       "24                       Valine           Val      V\n",
       "25   Glutamine or glutamic acid           Glx      Z"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Lookup Table\n",
    "amino_name_lookup = amino_table[amino_table.columns[:3]]\n",
    "amino_name_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create table of transformed variants along with their properties\n",
    "variant_properties = all_transformed.merge(amino_table[amino_table.columns[2:]], how='left',\n",
    "                 left_on='amino_state0', right_on='Letter', suffixes=('', '_'))\n",
    "variant_properties = variant_properties.merge(amino_table[amino_table.columns[2:]], how='left',\n",
    "                 left_on='amino_state1', right_on='Letter', suffixes=('_state0', '_state1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variant_properties_data = pd.concat([variant_properties[variant_properties.columns[:1]],\n",
    "                                pd.get_dummies(variant_properties[variant_properties.columns[1:]])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate table into training-test\n",
    "train_variant_properties = variant_properties_data[:train_variants.shape[0]].drop('Class', axis=1).fillna(0)\n",
    "test_variant_properties = variant_properties_data[train_variants.shape[0]:].reset_index(drop=True).drop('Class', axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_variant_properties = np.array(train_variant_properties)\n",
    "test_variant_properties = np.array(test_variant_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5668, 10817)"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_variant_properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>protein_token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>protein_token_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fusion0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fusion1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fusion_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>exon_n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>exon_action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>exon_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>genes_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>genes_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>genes_action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>genes_action_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>genes_action_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>amino_action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>amino_action_key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>amino_action_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>amino_standard_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>amino_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>amino_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>type_token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>type_token_bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>amino_standard_bool_token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Letter_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hydropathy\\r\\n(3 classes)_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Volume\\r\\n(5 classes)_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Chemical\\r\\n (7 classes)_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Physicochemical\\r\\n(11 classes)_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Charge\\r\\n(3 classes)_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Polarity\\r\\n(2 classes)_state0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Hydrogen donor or acceptor atom\\r\\n(4 classes)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Letter_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Hydropathy\\r\\n(3 classes)_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Volume\\r\\n(5 classes)_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Chemical\\r\\n (7 classes)_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Physicochemical\\r\\n(11 classes)_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Charge\\r\\n(3 classes)_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Polarity\\r\\n(2 classes)_state1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Hydrogen donor or acceptor atom\\r\\n(4 classes)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0                                               Class\n",
       "1                                                Gene\n",
       "2                                                  ID\n",
       "3                                           Variation\n",
       "4                                       protein_token\n",
       "5                                  protein_token_bool\n",
       "6                                             fusion0\n",
       "7                                             fusion1\n",
       "8                                         fusion_bool\n",
       "9                                              exon_n\n",
       "10                                        exon_action\n",
       "11                                          exon_bool\n",
       "12                                       genes_state0\n",
       "13                                       genes_state1\n",
       "14                                       genes_action\n",
       "15                                   genes_action_key\n",
       "16                                  genes_action_bool\n",
       "17                                       amino_action\n",
       "18                                   amino_action_key\n",
       "19                                  amino_action_bool\n",
       "20                                amino_standard_bool\n",
       "21                                       amino_state0\n",
       "22                                       amino_state1\n",
       "23                                         type_token\n",
       "24                                    type_token_bool\n",
       "25                          amino_standard_bool_token\n",
       "26                                      Letter_state0\n",
       "27                   Hydropathy\\r\\n(3 classes)_state0\n",
       "28                       Volume\\r\\n(5 classes)_state0\n",
       "29                    Chemical\\r\\n (7 classes)_state0\n",
       "30             Physicochemical\\r\\n(11 classes)_state0\n",
       "31                       Charge\\r\\n(3 classes)_state0\n",
       "32                     Polarity\\r\\n(2 classes)_state0\n",
       "33  Hydrogen donor or acceptor atom\\r\\n(4 classes)...\n",
       "34                                      Letter_state1\n",
       "35                   Hydropathy\\r\\n(3 classes)_state1\n",
       "36                       Volume\\r\\n(5 classes)_state1\n",
       "37                    Chemical\\r\\n (7 classes)_state1\n",
       "38             Physicochemical\\r\\n(11 classes)_state1\n",
       "39                       Charge\\r\\n(3 classes)_state1\n",
       "40                     Polarity\\r\\n(2 classes)_state1\n",
       "41  Hydrogen donor or acceptor atom\\r\\n(4 classes)..."
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(variant_properties.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_metrics(s, n):\n",
    "    explained_variance = s.explained_variance_ratio_.sum()\n",
    "    #     print_op = \"Explained variance of SVD with {} features: {}%\"\n",
    "    #     print(print_op.format(n, int(explained_variance * 100)))\n",
    "    return explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_fn(data_train, data_test=None, target=None, n_features=20, test_transform=False, plotting=False):\n",
    "    t = time.time()\n",
    "    print(\"Beginning svd on training data\", end=\"\\r\")\n",
    "    #svd = TruncatedSVD(n_features, algorithm='arpack')\n",
    "    pca = PCA(n_features)\n",
    "    pca_train = pca.fit_transform(data_train)\n",
    "    print(print_op_str(\"train\").format(time.time()-t), end=\"\\r\")\n",
    "    \n",
    "    if test_transform == True:\n",
    "        print(\"Beginning pca on test data\", end=\"\\r\")\n",
    "        pca_test = pca.transform(data_test)\n",
    "        print(print_op_str(\"test\").format(time.time()-t), end=\"\\r\")\n",
    "        print_blank(len(print_op_str(\"test\")))\n",
    "    else:\n",
    "        pca_test = sps.csr_matrix((1,1))\n",
    "        print_blank(len(print_op_str(\"train\")))\n",
    "        \n",
    "    total_explained_variance = pca_metrics(pca, n_features)\n",
    "        \n",
    "    if plotting == True:\n",
    "        data2D_pca = pca_train\n",
    "        plt.scatter(data2D_pca[:,0], data2D_pca[:,1], c=target)\n",
    "        plt.show()  \n",
    "        \n",
    "    return pca, pca_train, pca_test, total_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_n_pca = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mini, pca_train_mini, pca_test_mini, tev_pca_mini = svd_fn(train_variant_properties, \n",
    "                                                 test_variant_properties, \n",
    "                                                 y_train, \n",
    "                                                 features_n_pca, \n",
    "                                                 test_transform=False, \n",
    "                                                 plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = train_variant_properties.shape[1]\n",
    "output_shape = len(train['Class'].unique())\n",
    "batch_n = 32\n",
    "EPOCHS_N = 10 #100\n",
    "model_save_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_hypothesis():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=input_shape, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_shape, kernel_initializer='normal', activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_resume():\n",
    "    model = load_recent_model(model_path)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Callback for saving model and weights at n intervals in training\n",
    "# https://keras.io/callbacks/#modelcheckpoint\n",
    "weight_save_callback = ModelCheckpoint(model_path + '.{epoch:02d}-{loss:.2f}.hdf5', \n",
    "                                       monitor='loss', \n",
    "                                       verbose=0, \n",
    "                                       save_best_only=True, \n",
    "                                       mode='auto',\n",
    "                                       period=model_save_interval # Interval (number of epochs) between checkpoints\n",
    "                                      )\n",
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=50, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot = LabelEncoder()\n",
    "onehot.fit(y_train)\n",
    "y_enc = onehot.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ind = np_utils.to_categorical(y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to restore previous checkpoints to continue training\n",
    "if os.path.isfile(model_path + '.h5') and os.path.isfile(model_path + '.json'):\n",
    "    estimator = KerasClassifier(build_fn=model_resume, epochs=EPOCHS_N, batch_size=batch_n)\n",
    "    model = model_resume()\n",
    "else:\n",
    "    estimator = KerasClassifier(build_fn=model_hypothesis, epochs=EPOCHS_N, batch_size=batch_n)\n",
    "    model = model_hypothesis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Or create a new one\n",
    "estimator = KerasClassifier(build_fn=model_hypothesis, epochs=EPOCHS_N, batch_size=batch_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3321/3321 [==============================] - 12s - loss: 2.9709 - acc: 0.1981    \n",
      "Epoch 2/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.9878 - acc: 0.2484    \n",
      "Epoch 3/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.9227 - acc: 0.2569    \n",
      "Epoch 4/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8931 - acc: 0.2686    \n",
      "Epoch 5/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8589 - acc: 0.2662    \n",
      "Epoch 6/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8474 - acc: 0.2776    \n",
      "Epoch 7/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8423 - acc: 0.2764    \n",
      "Epoch 8/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8408 - acc: 0.2803    \n",
      "Epoch 9/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8470 - acc: 0.2815    \n",
      "Epoch 10/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8343 - acc: 0.2776    \n",
      "Epoch 11/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8376 - acc: 0.2849    \n",
      "Epoch 12/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8343 - acc: 0.2864    \n",
      "Epoch 13/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8338 - acc: 0.2876    \n",
      "Epoch 14/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8269 - acc: 0.2830    \n",
      "Epoch 15/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8280 - acc: 0.2867    \n",
      "Epoch 16/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8344 - acc: 0.2858    \n",
      "Epoch 17/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8281 - acc: 0.2861    \n",
      "Epoch 18/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8290 - acc: 0.2867    \n",
      "Epoch 19/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8260 - acc: 0.2891    \n",
      "Epoch 20/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8273 - acc: 0.2843    \n",
      "Epoch 21/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8313 - acc: 0.2758    \n",
      "Epoch 22/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8284 - acc: 0.2836    \n",
      "Epoch 23/100\n",
      "3321/3321 [==============================] - 11s - loss: 1.8293 - acc: 0.2818    \n",
      "Epoch 24/100\n",
      "2656/3321 [======================>.......] - ETA: 2s - loss: 1.8246 - acc: 0.2858"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-799-f2c65990d635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start_time = time.time()\\n#estimator.fit(svd_train, y_ind, validation_split=0.05)\\nestimator.fit(np.array(train_variant_properties), y_ind, batch_size=batch_n, epochs=EPOCHS_N*10, callbacks=[weight_save_callback, early_stopping])\\nend_time = time.time()\\nprint(\"Elapsed time: {:.2f} sec\".format(end_time-start_time))\\ntry: \\n    save_model_to_json(estimator, model_path)\\n    print(\"Saved model and weights to disk\")\\nexcept Exception as e:\\n    print(e)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Reynard/anaconda/envs/W207-final/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "#estimator.fit(svd_train, y_ind, validation_split=0.05)\n",
    "estimator.fit(np.array(train_variant_properties), y_ind, batch_size=batch_n, epochs=EPOCHS_N*10, callbacks=[weight_save_callback, early_stopping])\n",
    "end_time = time.time()\n",
    "print(\"Elapsed time: {:.2f} sec\".format(end_time-start_time))\n",
    "try: \n",
    "    save_model_to_json(estimator, model_path)\n",
    "    print(\"Saved model and weights to disk\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = estimator.predict_proba(svd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(y_pred)\n",
    "submission['id'] = test_index\n",
    "submission.columns = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'id']\n",
    "submission.to_csv(data_directory + \"/output/submission_\" + str(int(time.time())) + \".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_train = X_train['Text']\n",
    "corpus_test = X_test['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sparse_metrics(transformer_type, sparse_mtx):\n",
    "    print(\"Vocabulary length: {}\".format(len(transformer_type.vocabulary_)))\n",
    "    print('sparse matrix shape: {}'.format(sparse_mtx.shape))\n",
    "    print('nonzero count: {}'.format(sparse_mtx.nnz))\n",
    "    print('sparsity: {:.2f}'.format((100.0 * sparse_mtx.nnz / (sparse_mtx.shape[0] * sparse_mtx.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_func(X, Y, ngrams=1, plotting=False):\n",
    "    t = time.time()\n",
    "    tfidf = TfidfVectorizer(stop_words = 'english', ngram_range=(1, ngrams), sublinear_tf=True, use_idf=True)\n",
    "    tfidf_train = tfidf.fit_transform(X)\n",
    "    print(print_op_str(\"train\").format(time.time()-t), end=\"\\r\")\n",
    "    tfidf_test = tfidf.transform(Y)\n",
    "    print(print_op_str(\"test\").format(time.time()-t), end=\"\\r\")\n",
    "    print_blank(len(print_op_str(\"test\")))\n",
    "    \n",
    "    print_op = \"Shape: {}\\nNon-zero mean: {}\\nNon-zero median: {}\"\n",
    "    mean_nnz = int(round(np.mean(tfidf_train.getnnz(1))))\n",
    "    median_nnz = int(round(np.median(tfidf_train.getnnz(1))))\n",
    "    print(print_op.format(tfidf_train.shape, mean_nnz,median_nnz))\n",
    "    print(\"\\nDone in {:.2f} seconds\".format(time.time()-t))\n",
    "    \n",
    "    if plotting == True:     \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        plt.plot(np.sort(tfidf_train.getnnz(1))[::-1])\n",
    "\n",
    "        # Log transformed\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(np.sort(np.log(tfidf_train.getnnz(1)))[::-1])\n",
    "        \n",
    "    return tfidf, tfidf_train, tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', ngram_range=(1, 2), sublinear_tf=True, use_idf=True)\n",
    "tfidf_train = tfidf.fit_transform(corpus_train)\n",
    "tfidf_test = tfidf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw = stopwords\n",
    "stopwrds = sw.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_preprocessor(s, action=1):\n",
    "    \n",
    "    # lowercase (this is already defaulted in Count Vectorizer)\n",
    "    s = s.lower()\n",
    "    \n",
    "    # Regex functions\n",
    "    def regexer(s, keep=None):\n",
    "        \n",
    "        # remove numbers at end of words that might be citations or other misleading modifiers\n",
    "        if keep == \"no_citations\":\n",
    "            if s.lower() not in tt_corpus:\n",
    "                regex = r\"^[^a-zA-z]*|[^a-zA-Z]*$\"\n",
    "                \n",
    "        # remove all numbers in words that might be citations or other misleading modifiers\n",
    "        if keep == \"no_numbers\":\n",
    "            if s.lower() not in tt_corpus:\n",
    "                regex = r\"[^a-zA-Z ]\"\n",
    "            \n",
    "        # Apply Regex transformation\n",
    "        s = re.sub(regex, \"\", s, 0)\n",
    "        return s\n",
    "    \n",
    "    # Remove stop words\n",
    "    def stopwords(s):\n",
    "        \n",
    "        # Use nltk function for tokenization\n",
    "        tokens = word_tokenize(s) \n",
    "        \n",
    "        # Get stopwords list from nltk.corpus and remove words in the list\n",
    "        s_bin = [w for w in tokens if not w in stopwrds]\n",
    "        s = ' '.join(s_bin)\n",
    "        return s\n",
    "    \n",
    "    # Lemmatize or stem function\n",
    "    def lemmatize(s, func=\"stem\"):\n",
    "        # Split string into individual tokens\n",
    "        tokens = word_tokenize(s) \n",
    "        s_bin = []\n",
    "        \n",
    "        # Stem tokens\n",
    "        if func == \"stem\":\n",
    "            fn = PorterStemmer().stem\n",
    "        # Lemmatization\n",
    "        if func == \"lemma\":\n",
    "            fn = WordNetLemmatizer().lemmatize\n",
    "        \n",
    "        for t in tokens:\n",
    "            s_bin.append(fn(t))\n",
    "        s = ' '.join(s_bin)\n",
    "        return s\n",
    "    \n",
    "    # Select transformation based on `action` parameter\n",
    "    if 0 in action:\n",
    "        s = regexer(s, keep=\"no_citations\")\n",
    "    if 1 in action:\n",
    "        s = regexer(s, keep=\"no_numbers\")\n",
    "    if 2 in action:\n",
    "        s = stopwords(s)\n",
    "    if 3 in action:\n",
    "        s = lemmatize(s, \"lemma\")\n",
    "    if 4 in action:\n",
    "        s = lemmatize(s, \"stem\")\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(preprocessor=lambda x: text_preprocessor(x, action=[0, 2, 3]), \n",
    "                     lowercase=True, \n",
    "                     stop_words='english', \n",
    "                     min_df=1, \n",
    "                     max_df=.1, \n",
    "                     ngram_range=(1,2))\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_cv = cv.fit_transform(corpus_train)\n",
    "test_cv = cv.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_fn(X, Y, ngrams=1, mn=1, mx=0.1, test_transform=False, plotting=False):\n",
    "    t = time.time()\n",
    "    tfidf = TfidfVectorizer(stop_words = 'english', \n",
    "                            ngram_range=(1, ngrams), \n",
    "                            sublinear_tf=True, \n",
    "                            use_idf=True, \n",
    "                            preprocessor=lambda x: text_preprocessor(x, action=[0, 2, 3]), \n",
    "                            lowercase=True, \n",
    "                            min_df=mn, \n",
    "                            max_df=mx)\n",
    "    print(\"Beginning tf-idf on training data\", end=\"\\r\")\n",
    "    tfidf_train = tfidf.fit_transform(X)\n",
    "    print(print_op_str(\"train\").format(time.time()-t), end=\"\\r\")\n",
    "    \n",
    "    if test_transform == True:\n",
    "        print(\"Beginning tf-idf on test data\", end=\"\\r\")\n",
    "        tfidf_test = tfidf.transform(Y)\n",
    "        print(print_op_str(\"test\").format(time.time()-t), end=\"\\r\")\n",
    "        print_blank(len(print_op_str(\"test\")))\n",
    "    else:\n",
    "        tfidf_test = sps.csr_matrix((1,1))\n",
    "        print_blank(len(print_op_str(\"train\")))\n",
    "    \n",
    "    print_op = \"Shape: {}\\nNon-zero mean: {}\\nNon-zero median: {}\"\n",
    "    mean_nnz = int(round(np.mean(tfidf_train.getnnz(1))))\n",
    "    median_nnz = int(round(np.median(tfidf_train.getnnz(1))))\n",
    "    print(print_op.format(tfidf_train.shape, mean_nnz,median_nnz))\n",
    "    print(\"\\nDone in {:.2f} seconds\".format(time.time()-t))\n",
    "    \n",
    "    if plotting == True:     \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        plt.plot(np.sort(tfidf_train.getnnz(1))[::-1])\n",
    "\n",
    "        # Log transformed\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(np.sort(np.log(tfidf_train.getnnz(1)))[::-1])\n",
    "        \n",
    "    return tfidf, tfidf_train, tfidf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svd_metrics(s, n):\n",
    "    explained_variance = s.explained_variance_ratio_.sum()\n",
    "    #     print_op = \"Explained variance of SVD with {} features: {}%\"\n",
    "    #     print(print_op.format(n, int(explained_variance * 100)))\n",
    "    return explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svd_fn(data_train, data_test=None, target=None, n_features=20, test_transform=False, plotting=False):\n",
    "    t = time.time()\n",
    "    print(\"Beginning svd on training data\", end=\"\\r\")\n",
    "    svd = TruncatedSVD(n_features, algorithm='arpack')\n",
    "    svd_train = svd.fit_transform(data_train)\n",
    "    print(print_op_str(\"train\").format(time.time()-t), end=\"\\r\")\n",
    "    \n",
    "    if test_transform == True:\n",
    "        print(\"Beginning svd on test data\", end=\"\\r\")\n",
    "        svd_test = svd.transform(data_test)\n",
    "        print(print_op_str(\"test\").format(time.time()-t), end=\"\\r\")\n",
    "        print_blank(len(print_op_str(\"test\")))\n",
    "    else:\n",
    "        svd_test = sps.csr_matrix((1,1))\n",
    "        print_blank(len(print_op_str(\"train\")))\n",
    "        \n",
    "    total_explained_variance = svd_metrics(svd, n_features)\n",
    "        \n",
    "    if plotting == True:\n",
    "        data2D_svd = svd_train\n",
    "        plt.scatter(data2D_svd[:,0], data2D_svd[:,1], c=target)\n",
    "        plt.show()  \n",
    "        \n",
    "    return svd, svd_train, svd_test, total_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_n_svd = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10116"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_obj = [\n",
    "    X_train['Gene'],\n",
    "    X_train['Variation'],\n",
    "    X_test['Gene'],\n",
    "    X_test['Variation']\n",
    "]\n",
    "\n",
    "tt_corpus = []\n",
    "[tt_corpus.extend(df.values.tolist()) for df in corpus_obj]\n",
    "tt_corpus = pd.Series(tt_corpus)\n",
    "tt_corpus = [s.lower() for s in list(tt_corpus.unique())]\n",
    "len(tt_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename + '.npz')\n",
    "    return sps.csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Restore TF-IDF or run TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Tokenize data (this will take a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tfidf, tfidf_train, tfidf_test = tfidf_fn(corpus_train,\n",
    "#                                 corpus_test,\n",
    "#                                 ngrams=2, \n",
    "#                                 mn=1, \n",
    "#                                 mx=0.1, \n",
    "#                                 test_transform=True, \n",
    "#                                 plotting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to save afterward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_sparse_csr(data_directory + '/data/train_bigram_vocabulary', tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_sparse_csr(data_directory + '/data/test_bigram_vocabulary', tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, load previoiusly tokenized vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 927 ms, sys: 414 ms, total: 1.34 s\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_train = load_sparse_csr(data_directory + '/data/train_bigram_vocabulary')\n",
    "tfidf_test = load_sparse_csr(data_directory + '/data/test_bigram_vocabulary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore SVD features or run SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SVD on data (also takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# svd = TruncatedSVD(features_n_svd, algorithm='arpack')\n",
    "# svd_train = svd.fit_transform(tfidf_train)\n",
    "# svd_test = svd.transform(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(data_directory + '/data/train_svd_200', svd_train)\n",
    "# np.save(data_directory + '/data/test_svd_200', svd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, load previously saved data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd_train = np.load(data_directory + '/data/train_svd_200.npy')\n",
    "svd_test = np.load(data_directory + '/data/test_svd_200.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Concatenate SVD with features created with transformation along with amino properties info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hybrid_train = np.concatenate((svd_train, train_variant_properties), axis=1)\n",
    "hybrid_test = np.concatenate((svd_test, test_variant_properties), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  Hyperparameters **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = hybrid_train.shape[1]\n",
    "output_shape = len(train['Class'].unique())\n",
    "batch_n = 32\n",
    "EPOCHS_N = 100\n",
    "model_save_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same model that worked well with only text features (hidden units => `512` => `256` => `128` => `64`), then (`64` => `128` => `256` => `512`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_hypothesis():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=input_shape, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_shape, kernel_initializer='normal', activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_resume():\n",
    "    model = load_recent_model(model_path)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Callback for saving model and weights at n intervals in training\n",
    "# https://keras.io/callbacks/#modelcheckpoint\n",
    "weight_save_callback = ModelCheckpoint(model_path + '.{epoch:02d}-{loss:.2f}.hdf5', \n",
    "                                       monitor='loss', \n",
    "                                       verbose=0, \n",
    "                                       save_best_only=True, \n",
    "                                       mode='auto',\n",
    "                                       period=model_save_interval # Interval (number of epochs) between checkpoints\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=50, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot = LabelEncoder()\n",
    "onehot.fit(y_train)\n",
    "y_enc = onehot.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ind = np_utils.to_categorical(y_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Model or Begin Training New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restore a previously saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model at checkpoint: /Users/Reynard/dropbox/Data/kaggle/Personalized Medicine/saved_models/model_001.199-1.51.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Try to restore previous checkpoints to continue training\n",
    "if os.path.isfile(model_path + '.h5') and os.path.isfile(model_path + '.json'):\n",
    "    estimator = KerasClassifier(build_fn=model_resume, epochs=EPOCHS_N, batch_size=batch_n)\n",
    "    model = model_resume()\n",
    "else:\n",
    "    estimator = KerasClassifier(build_fn=model_hypothesis, epochs=EPOCHS_N, batch_size=batch_n)\n",
    "    model = model_hypothesis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=model_hypothesis, epochs=EPOCHS_N, batch_size=batch_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model at checkpoint: /Users/Reynard/dropbox/Data/kaggle/Personalized Medicine/saved_models/model_001.199-1.51.hdf5\n",
      "Epoch 1/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.5030 - acc: 0.4330    \n",
      "Epoch 2/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4397 - acc: 0.4625    \n",
      "Epoch 3/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.4407 - acc: 0.4523    \n",
      "Epoch 4/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5061 - acc: 0.4402    - ETA: 0s - loss: 1.5013 - acc:\n",
      "Epoch 5/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.4426 - acc: 0.4616     \n",
      "Epoch 6/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5033 - acc: 0.4372    \n",
      "Epoch 7/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.4817 - acc: 0.4399    \n",
      "Epoch 8/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.4791 - acc: 0.4460    \n",
      "Epoch 9/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5519 - acc: 0.4041    \n",
      "Epoch 10/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.5018 - acc: 0.4303    \n",
      "Epoch 11/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.4701 - acc: 0.4478    \n",
      "Epoch 12/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4672 - acc: 0.4475    \n",
      "Epoch 13/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4987 - acc: 0.4417    - ETA: 5s - loss: 1.4693 - acc: 0.45 - ETA: 5s - loss: 1.472\n",
      "Epoch 14/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5650 - acc: 0.4231    \n",
      "Epoch 15/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5135 - acc: 0.4333    \n",
      "Epoch 16/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.4663 - acc: 0.4481    \n",
      "Epoch 17/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4627 - acc: 0.4526    \n",
      "Epoch 18/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5256 - acc: 0.4243    \n",
      "Epoch 19/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.5279 - acc: 0.4225     \n",
      "Epoch 20/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.4934 - acc: 0.4300     \n",
      "Epoch 21/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5245 - acc: 0.4312    \n",
      "Epoch 22/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4924 - acc: 0.4381    \n",
      "Epoch 23/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4701 - acc: 0.4520    - ETA: 1s - loss: 1.473\n",
      "Epoch 24/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4641 - acc: 0.4538    \n",
      "Epoch 25/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4735 - acc: 0.4493    \n",
      "Epoch 26/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4365 - acc: 0.4613    \n",
      "Epoch 27/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4107 - acc: 0.4523    \n",
      "Epoch 28/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4211 - acc: 0.4550    \n",
      "Epoch 29/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.4319 - acc: 0.4496     \n",
      "Epoch 30/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.4253 - acc: 0.4529    \n",
      "Epoch 31/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5037 - acc: 0.4381    \n",
      "Epoch 32/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4979 - acc: 0.4357    \n",
      "Epoch 33/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.4402 - acc: 0.4541    \n",
      "Epoch 34/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4731 - acc: 0.4369    \n",
      "Epoch 35/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5873 - acc: 0.3981    \n",
      "Epoch 36/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5049 - acc: 0.4303    \n",
      "Epoch 37/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4445 - acc: 0.4456    \n",
      "Epoch 38/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4209 - acc: 0.4562    - ETA: 1s - loss: 1\n",
      "Epoch 39/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4790 - acc: 0.4420    \n",
      "Epoch 40/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5141 - acc: 0.4333    \n",
      "Epoch 41/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4339 - acc: 0.4535    \n",
      "Epoch 42/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5680 - acc: 0.4095    \n",
      "Epoch 43/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5963 - acc: 0.3797    \n",
      "Epoch 44/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5843 - acc: 0.3963    \n",
      "Epoch 45/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.6040 - acc: 0.3818    \n",
      "Epoch 46/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5914 - acc: 0.3827    \n",
      "Epoch 47/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.6226 - acc: 0.3547    \n",
      "Epoch 48/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5689 - acc: 0.4047    \n",
      "Epoch 49/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4756 - acc: 0.4384    \n",
      "Epoch 50/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5653 - acc: 0.3960    \n",
      "Epoch 51/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5514 - acc: 0.4095    \n",
      "Epoch 52/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.5888 - acc: 0.3866     \n",
      "Epoch 53/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.5920 - acc: 0.3824     \n",
      "Epoch 54/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.6636 - acc: 0.3219    \n",
      "Epoch 55/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.6151 - acc: 0.3586    \n",
      "Epoch 56/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.6198 - acc: 0.3577    \n",
      "Epoch 57/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.6500 - acc: 0.3345    \n",
      "Epoch 58/1000\n",
      "3321/3321 [==============================] - 11s - loss: 1.5670 - acc: 0.3743    \n",
      "Epoch 59/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.6220 - acc: 0.3550    \n",
      "Epoch 60/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5785 - acc: 0.3875    \n",
      "Epoch 61/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.6349 - acc: 0.3418    - E\n",
      "Epoch 62/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5650 - acc: 0.3839    \n",
      "Epoch 63/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5795 - acc: 0.3836    \n",
      "Epoch 64/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5671 - acc: 0.3812    \n",
      "Epoch 65/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5378 - acc: 0.4074    \n",
      "Epoch 66/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5472 - acc: 0.3966    \n",
      "Epoch 67/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5225 - acc: 0.4140    \n",
      "Epoch 68/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.4841 - acc: 0.4399     \n",
      "Epoch 69/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.5220 - acc: 0.4213     \n",
      "Epoch 70/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.5544 - acc: 0.4080     - ETA:\n",
      "Epoch 71/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5797 - acc: 0.3866    \n",
      "Epoch 72/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5846 - acc: 0.3836    - ETA: 1s - loss: 1.5752 \n",
      "Epoch 73/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5827 - acc: 0.3770    \n",
      "Epoch 74/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5245 - acc: 0.4270    \n",
      "Epoch 75/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.5445 - acc: 0.4167    \n",
      "Epoch 76/1000\n",
      "3321/3321 [==============================] - 10s - loss: 1.4740 - acc: 0.4354    \n",
      "Epoch 77/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.5405 - acc: 0.4140     \n",
      "Epoch 78/1000\n",
      "3321/3321 [==============================] - 9s - loss: 1.5748 - acc: 0.3830     \n",
      "Epoch 00077: early stopping\n",
      "Elapsed time: 825.05 sec\n",
      "Saved model and weights to disk\n",
      "CPU times: user 38min 5s, sys: 9min 34s, total: 47min 40s\n",
      "Wall time: 13min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "#estimator.fit(svd_train, y_ind, validation_split=0.05)\n",
    "estimator.fit(hybrid_train, y_ind, batch_size=batch_n, epochs=EPOCHS_N*10, callbacks=[weight_save_callback, early_stopping])\n",
    "end_time = time.time()\n",
    "print(\"Elapsed time: {:.2f} sec\".format(end_time-start_time))\n",
    "try: \n",
    "    save_model_to_json(estimator, model_path)\n",
    "    print(\"Saved model and weights to disk\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display model architecture\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_hypothesis()).create(prog='dot', format='svg'))\n",
    "\n",
    "# Save to .png\n",
    "from keras.utils import plot_model\n",
    "plot_model(model_hypothesis(), to_file='model_hypothesis1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5184/5668 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = estimator.predict_proba(hybrid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(y_pred)\n",
    "submission['id'] = test_index\n",
    "submission.columns = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'id']\n",
    "submission.to_csv(data_directory + \"/output/submission_\" + str(int(time.time())) + \".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:W207-final]",
   "language": "python",
   "name": "conda-env-W207-final-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
